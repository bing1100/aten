{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43facd20",
   "metadata": {},
   "source": [
    "# NER using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178030c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d77e14",
   "metadata": {},
   "source": [
    "## Load pretrained bio / med spacy models\n",
    "\n",
    "1. git clone spacy ner models\n",
    "2. load these models in\n",
    "\n",
    "This avoids needing to do further fine-tuning or training (since we already achieve 100% accuracy on the provided data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1fe54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhux/anaconda3/envs/aten/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_med7_lg' (3.4.2.1) was trained with spaCy v3.4.2 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/bhux/anaconda3/envs/aten/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_ner_bc5cdr_md' (0.5.1) was trained with spaCy v3.4.1 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# git clone https://huggingface.co/kormilitzin/en_core_med7_lg ./model/\n",
    "# git clone https://huggingface.co/Kaelan/en_ner_bc5cdr_md ./model/\n",
    "\n",
    "dose_nlp = spacy.load(\"./model/en_core_med7_lg\")\n",
    "symptom_nlp = spacy.load(\"./model/en_ner_bc5cdr_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6de280",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "1. convert data to standard ner format - i.e. (sentence, [{tag, spans}...])\n",
    "2. analyze unique words in dataset for ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9908b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv('./data/ner_data.csv')\n",
    "\n",
    "ner_words = {}\n",
    "raw_data = {}\n",
    "for _, row in df.iterrows():\n",
    "\n",
    "    # Create word_list\n",
    "    if row[\"sentence_id\"] not in raw_data:\n",
    "        raw_data[row['sentence_id']] = {\n",
    "            'word_list':[],\n",
    "            'label_list':[]\n",
    "        }\n",
    "    raw_data[row['sentence_id']]['word_list'].append(row['word'])\n",
    "    raw_data[row['sentence_id']]['label_list'].append(row['tag'])\n",
    "\n",
    "    # For analytics\n",
    "    if row['tag'] not in ner_words:\n",
    "        ner_words[row['tag']] = []\n",
    "    ner_words[row['tag']].append(row['word'])\n",
    "\n",
    "# create ner_data\n",
    "ner_data = {}\n",
    "for k,v in raw_data.items():\n",
    "    word_list = raw_data[k]['word_list']\n",
    "    label_list = raw_data[k]['label_list']\n",
    "\n",
    "    nlabels = []\n",
    "    starts = []\n",
    "    ends = []\n",
    "    start = 0\n",
    "    for w, l in zip(word_list, label_list):\n",
    "        end = start + len(w)\n",
    "        if l != \"O\":\n",
    "            nlabels.append((w, l))\n",
    "            starts.append(start)\n",
    "            ends.append(end)\n",
    "        start = end + 1\n",
    "    \n",
    "    ner_data[k] = {}\n",
    "    ner_data[k]['label'] = nlabels\n",
    "    ner_data[k]['sentence'] = \" \".join(word_list)\n",
    "    ner_data[k]['true'] = [{\n",
    "        \"label\": l,\n",
    "        \"start\": s,\n",
    "        \"end\": e\n",
    "    } for (_, l), s, e in zip(nlabels, starts, ends)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11fd3f",
   "metadata": {},
   "source": [
    "## Create mappings from imported models to our desired NER task\n",
    "\n",
    "1. compute imported model NER tags for our desired vocabulary\n",
    "2. map imported model ner tags to our desired tags onver our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b266a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more to this vocab if needed \n",
    "dosage_vocab = list(set(ner_words['B-DOSAGE']))\n",
    "symptom_vocab = list(set(ner_words['B-SYMPTOM']))\n",
    "\n",
    "doses = dose_nlp(\" split \".join(dosage_vocab))\n",
    "symptoms = symptom_nlp(\" split \".join(symptom_vocab))\n",
    "\n",
    "dose_vocab_nlp = [(ent.text, ent.label_) for ent in doses.ents]\n",
    "symptoms_vocab_nlp = [(ent.text, ent.label_) for ent in symptoms.ents]\n",
    "\n",
    "dose_map = {\n",
    "    l : 'B-DOSAGE'\n",
    "    for _,l in dose_vocab_nlp\n",
    "}\n",
    "\n",
    "symptoms_map = {\n",
    "    l : 'B-SYMPTOM'\n",
    "    for _,l in symptoms_vocab_nlp\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba2a95",
   "metadata": {},
   "source": [
    "## NER for drug names\n",
    "\n",
    "Note: drug names are not properly included in the provided dataset / are not labelled properly\n",
    "\n",
    "1. download all FDA drugs in US (1939-Present) https://www.kaggle.com/datasets/protobioengineering/united-states-fda-drugs-feb-2024?resource=download\n",
    "2. create drug name vocabulary from all FDA drugs\n",
    "3. utilize string matching to create logical NER function \n",
    "\n",
    "This method makes it easier to add or remove drugs based on country and over time - without needing to retrain\n",
    "\n",
    "fuzzy matching algorithms could be applied here but are out of scope of our work right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a577193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7797\n",
      "['aminosyn ii 4.25% in dextrose 20% in plastic container', 'beclovent', 'eskalith', 'proquin xr', 'linaclotide']\n"
     ]
    }
   ],
   "source": [
    "drug_df = pd.read_csv('./data/drugs.csv')[\"brand_name\"]\n",
    "print()\n",
    "drug_vocab = []\n",
    "for name in drug_df.tolist():\n",
    "    drug_vocab += [d.strip() for d in name.lower().replace(' and', ',').split(',')]\n",
    "drug_vocab += [\"drug\"]\n",
    "\n",
    "drug_vocab = set(drug_vocab) \n",
    "drug_vocab.remove('')\n",
    "print(len(drug_vocab))\n",
    "print(list(drug_vocab)[:5])\n",
    "\n",
    "def drug_str_match(sentence):\n",
    "    ret = []\n",
    "    for w in sentence.split(\" \"):\n",
    "        if w.lower() in drug_vocab:\n",
    "            ret.append((w, \"B-DrugName\"))\n",
    "        if \"drug\" in w.lower():\n",
    "            ret.append((w, \"B-DrugName\"))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955e6d92",
   "metadata": {},
   "source": [
    "## NER function for a single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7383cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ner(ent, ent_map):\n",
    "    return [{\n",
    "        \"label\": ent_map[ent.label_],\n",
    "        \"start\": ent.start_char,\n",
    "        \"end\": ent.end_char\n",
    "    } for ent in ent.ents if ent.label_ in ent_map]\n",
    "\n",
    "def process_sentence(sentence, readable=False):\n",
    "    doses_ner = dose_nlp(sentence)\n",
    "    symptoms_ner = symptom_nlp(sentence)\n",
    "    pred = convert_ner(doses_ner, dose_map) + convert_ner(symptoms_ner, symptoms_map)\n",
    "\n",
    "    if readable:\n",
    "        doses = [(ent.text, dose_map[ent.label_]) for ent in doses_ner.ents if ent.label_ in dose_map]\n",
    "        symptoms = [(ent.text, symptoms_map[ent.label_]) for ent in symptoms_ner.ents if ent.label_ in symptoms_map]\n",
    "        drugs = drug_str_match(sentence)\n",
    "        return doses + symptoms + drugs\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2498e0f9",
   "metadata": {},
   "source": [
    "## Batch NER inference with a group of sentences\n",
    "\n",
    "We would use batch NER for online inference - optimizing for both batch size and runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac83af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 97.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def batch_inference(ner_data):\n",
    "    sentences = [v['sentence'] for _, v in ner_data.items()]\n",
    "    preds = []\n",
    "    for sentence in tqdm(sentences):\n",
    "        preds.append(process_sentence(sentence))\n",
    "    return preds\n",
    "    \n",
    "preds = batch_inference(ner_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f26488",
   "metadata": {},
   "source": [
    "## Evaluate per tag - precision, recall, f1\n",
    "\n",
    "We reach 100% accuracy across all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92414c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-DOSAGE': {'ent_type': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 1000, 'actual': 1000, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'partial': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 1000, 'actual': 1000, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'strict': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 1000, 'actual': 1000, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'exact': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 1000, 'actual': 1000, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}, 'B-SYMPTOM': {'ent_type': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 1000, 'actual': 1000, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'partial': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 1000, 'actual': 1000, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'strict': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 1000, 'actual': 1000, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'exact': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 1000, 'actual': 1000, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}}\n"
     ]
    }
   ],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "true = [v['true'] for _, v in ner_data.items()]\n",
    "evaluator = Evaluator(true, preds, tags=['B-DOSAGE', 'B-SYMPTOM'])\n",
    "results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "print(results_per_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181eeb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients experienced fatigue during the course of 75mg of DrugB\n"
     ]
    }
   ],
   "source": [
    "print(ner_data[21]['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b565a862",
   "metadata": {},
   "source": [
    "## Example of Drug Name NER\n",
    "\n",
    "we are able to complete NER on all FDA drugs published since 1939-Present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc44a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('50mg', 'B-DOSAGE'), ('rash', 'B-SYMPTOM'), ('Aspirin', 'B-DrugName')]\n",
      "[('200mg', 'B-DOSAGE'), ('fever', 'B-SYMPTOM'), ('crestor', 'B-DrugName')]\n",
      "[('100mg', 'B-DOSAGE'), ('rash', 'B-SYMPTOM'), ('aminocaproic', 'B-DrugName')]\n",
      "[('432mg', 'B-DOSAGE'), ('fever', 'B-SYMPTOM'), ('DrugD', 'B-DrugName')]\n",
      "[('75mg', 'B-DOSAGE'), ('pain', 'B-SYMPTOM'), ('RIBASPHERE', 'B-DrugName')]\n"
     ]
    }
   ],
   "source": [
    "print(process_sentence(\"Patients were given 50mg of Aspirin and developed rash\", readable=True))\n",
    "print(process_sentence(\"Patients experienced fever post-treatment with 200mg of crestor\", readable=True))\n",
    "print(process_sentence(\"Patients experienced rash post-treatment with 100mg of aminocaproic\", readable=True))\n",
    "print(process_sentence(\"Patients experienced fever post-treatment with 432mg of DrugD\", readable=True))\n",
    "print(process_sentence(\"Patients experienced pain during the course of 75mg of RIBASPHERE\", readable=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
